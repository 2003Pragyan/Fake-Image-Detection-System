# Fake-Image-Detection-System
The overall objective of this project is to develop a model for detecting deepfake images that can distinguish between facial images as "real" or "fake" with high reliability. 
This task of classification is especially challenging because high-quality outputs are now being produced by cutting-edge GANs like StyleGAN2 and ProGAN. These models can produce human faces with elaborate textures, lighting effects, and expressions that closely resemble real-world visual features. Yet, even with their photorealism, GAN-produced images tend to leave behind minute imperfections—artefacts that are statistically recognizable by a trained deep learning model. These inconsistencies can range from unnatural skin textures, pixel-level distortions, misalignment of facial structures, irregular shadowing, and abnormities around facial borders or in blending with backgrounds. Though not visible to naked eyes, these imperfections are the building blocks of indicators for deepfake detection by machines.
To solve this intricate issue, the project adopts a multi-step process, starting with thorough data collection. Facial photos—real and synthetic—are gathered from publicly available benchmark datasets such as FaceForensics++, Celeb-DF, and the DeepFake Detection Challenge (DFDC). 
